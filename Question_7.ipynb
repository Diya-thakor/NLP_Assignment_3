{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOx59Vc4a8c6"
      },
      "source": [
        "## **Question 7:**\n",
        "# Write appropriate comments and rationale behind:\n",
        "(a) Lower or higher scores in the metrics.\n",
        "\n",
        "(b) Understanding from the number of parameters between pretraining and fine-tuning of the model.\n",
        "\n",
        "(c) Performance difference for the zero-shot and fine-tuned models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXImDh7Bnn4d"
      },
      "source": [
        "# **Analysis for SST2 Dataset:-**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**(a) Lower or higher scores in the metrics.**\n"
      ],
      "metadata": {
        "id": "uZiYVThv_P-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric       | Pre-trained (Zero-shot) | Fine-tuned | Difference | Change Direction |\n",
        "|--------------|-------------------------|------------|------------|------------------|\n",
        "| Accuracy     | 0.4850                  | 0.5100     | +0.0250    | Higher           |\n",
        "| Precision    | 0.4762                  | 0.5108     | +0.0346    | Higher           |\n",
        "| Recall       | 0.0980                  | 0.9314     | +0.8334    | Higher           |\n",
        "| F1-Score     | 0.1626                  | 0.6597     | +0.4971    | Higher           |"
      ],
      "metadata": {
        "id": "sp_jBH8P_fYO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bQ6alN1o9jL"
      },
      "source": [
        "###**(b) Understanding from the number of parameters between pretraining and fine-tuning of the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "843NluVppD13"
      },
      "source": [
        "\n",
        "Number of parameters in pre-trained model of squad:------> 1235814400\n",
        "\n",
        "Number of parameters in fine-tuned model of squad:-------> 1235818496\n",
        "\n",
        "**The difference in the number of parameters between the pre-trained and fine-tuned models is minimal: 4,096 parameters.**\n",
        "\n",
        "*The increase in parameters is consistent with a typical fine-tuning scenario where task-specific layers are added, but the pre-trained model's backbone remains largely intact. This approach ensures that the model adapts to the fine-tuning task without significantly increasing computational overhead.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN1_CW7dpLaV"
      },
      "source": [
        "###**(c) Performance difference for the zero-shot and fine-tuned models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJAFwkuUptne"
      },
      "source": [
        "**Pre-trained Model Metrics:**\n",
        "\n",
        "- **Accuracy: 0.4850:** Close to random chance for binary classification, indicating poor performance on the SST-2 task.\n",
        "\n",
        "- **Precision: 0.4762:** The model predicts some positive instances correctly, but its precision is relatively low.\n",
        "\n",
        "- **Recall: 0.0980:** Very low recall, meaning the model misses most positive instances.\n",
        "\n",
        "- **F1-Score: 0.1626:** The poor balance between precision and recall results in a low F1-score.\n",
        "\n",
        "**Fine-tuned Model Metrics:**\n",
        "\n",
        "- **Accuracy: 0.5100:** Slight improvement over the pre-trained model but still near random performance.\n",
        "\n",
        "- **Precision: 0.5108:** The model now predicts more positive instances correctly, showing a modest improvement in precision.\n",
        "\n",
        "- **Recall: 0.9314:** Significantly higher recall, meaning the model identifies almost all positive instances but may over-predict the positive class.\n",
        "\n",
        "- **F1-Score: 0.6597:** The improvement in both precision and recall results in a much better balance, reflected in the higher F1-score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL8iWb15nCr8"
      },
      "source": [
        "# **Analysis for Squad Dataset:-**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sC7U52nbEnw"
      },
      "source": [
        "###**(a) Lower or higher scores in the metrics.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW3c3MxLbKOf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "| Metric         | Fine-Tuned | Pre-Trained | Observation                            |\n",
        "|----------------|------------|-------------|----------------------------------------|\n",
        "| Exact Match    | 6.67       | 2.33        | Improved after fine-tuning.            |\n",
        "| F1 Score       | 2.84       | 2.79        | Negligible change.                     |\n",
        "| BLEU           | 0.0        | 21.36       | Drastic drop|\n",
        "| METEOR         | 0.018      | 0.020       | Slight decrease post fine-tuning.      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgHoHLz4fWa_"
      },
      "source": [
        "###**(b) Understanding from the number of parameters between pretraining and fine-tuning of the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz9YK0oQftqw"
      },
      "source": [
        "\n",
        "Number of parameters in pre-trained model of squad:------> 1235814400\n",
        "\n",
        "Number of parameters in fine-tuned model of squad:-------> 1235818498\n",
        "\n",
        "**The difference in the number of parameters between the pre-trained and fine-tuned models is minimal: 4,098 parameters.**\n",
        "\n",
        "*The increase in parameters is consistent with a typical fine-tuning scenario where task-specific layers are added, but the pre-trained model's backbone remains largely intact. This approach ensures that the model adapts to the fine-tuning task without significantly increasing computational overhead.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqENmRExjD7T"
      },
      "source": [
        "###**(c) Performance difference for the zero-shot and fine-tuned models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA09BadBhEBj"
      },
      "source": [
        "\n",
        "  **Key Observations and Potential Issues**\n",
        "\n",
        "\n",
        "  **Exact Match (EM):** Fine-tuning has led to a noticeable improvement, indicating better matching of answers with the ground truth.\n",
        "\n",
        "  **F1 Score:** The negligible change suggests the fine-tuned model is not effectively improving partial matches.\n",
        "\n",
        "  **BLEU:** A BLEU score of 0 for the fine-tuned model is unusual. This could indicate:\n",
        "  - A mismatch in the tokenization process.\n",
        "  The fine-tuned model generating outputs unrelated to the references.\n",
        "  Overfitting on the fine-tuning dataset leading to outputs not generalizing well.\n",
        "\n",
        "  **METEOR:** The decrease is minor, but its uggests the model is producing outputs less semantically aligned with the references."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kXImDh7Bnn4d",
        "pL8iWb15nCr8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}